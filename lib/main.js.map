{"version":3,"file":"main.js","sourceRoot":"","sources":["../src/main.ts"],"names":[],"mappings":";;AACA,0DAAqD;AAKrD,wCAAmC;AACnC,yCAAoC;AACpC,2CAA0C;AAM1C;IACC,IAAI,MAAM,GAAG,SAAS,CAAC,YAAY,CAAC,CAAC;IAErC,IAAI,KAAK,GAAG,qBAAW,CAAC,QAAQ,CAAC,aAAa,CAAC,CAAC;IAChD,IAAI,cAAc,GAAG,qBAAW,CAAC,iBAAiB,CAAC,KAAK,CAAC,CAAC;IAE1D,IAAI,MAAM,GAAG,IAAI,eAAM,CAAC,KAAK,EAAE,MAAM,EAAE,cAAc,CAAC,CAAC;IACvD,MAAM,CAAC,KAAK,EAAE,CAAC;AAChB,CAAC;AAED,IAAI,EAAE,CAAC;AAQP,mBAAmB,QAAgB;IAClC,IAAI,KAAK,GAAG,IAAI,eAAK,CAAC,QAAQ,CAAC,CAAC;IAEhC,IAAI,MAAM,GAAG,EAAE,CAAC;IAEhB,OAAO,IAAI,EAAE,CAAC;QACb,IAAI,SAAS,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QAClC,MAAM,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;QAEvB,EAAE,CAAC,CAAC,SAAS,CAAC,MAAM,EAAE,KAAK,aAAG,CAAC,GAAG,CAAC,CAAC,CAAC;YACpC,KAAK,CAAC;QACP,CAAC;IACF,CAAC;IAED,MAAM,CAAC,MAAM,CAAC;AACf,CAAC","sourcesContent":["\nimport RulesParser from \"./lexing/rules/RulesParser\";\nimport Rule from \"./lexing/rules/util/Rule\";\nimport { start } from \"repl\";\nimport Token from \"../lib/lexing/util/Token\";\n\nimport Lexer from './lexing/Lexer';\nimport Tag from './lexing/util/Tag';\nimport { Parser } from \"./parsing/Parser\";\n\n\n\n\n\nfunction main() {\n\tlet tokens = getTokens('./text.txt');\n\n\tlet rules = RulesParser.getRules('./testB.txt');\n\tlet grammarSymbols = RulesParser.getGrammarSymbols(rules);\n\n\tlet parser = new Parser(rules, tokens, grammarSymbols);\n\tparser.parse();\n}\n\nmain();\n\n\n\n\n\n\n\nfunction getTokens(fileName: string): Token[] {\n\tlet lexer = new Lexer(fileName);\n\n\tlet tokens = [];\n\n\twhile (true) {\n\t\tlet nextToken = lexer.nextToken();\n\t\ttokens.push(nextToken);\n\n\t\tif (nextToken.getTag() === Tag.EOF) {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn tokens;\n}\n"]}